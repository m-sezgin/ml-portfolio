{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression and Cross-Validation\n",
    "\n",
    "Note: This is a revised assignment originally called \"Homework 5\" from Professor Katherine Kinnaird's Machine Learning Spring 2021 course (CSC 294).\n",
    "\n",
    "Welcome to the first piece of machine learning for SDS 220! I'm excited to bridge the gap a little between intro stat and machine learning, because throughout both classes I've been thinking of ways concepts from one class could really complement concepts learned in the other. In this piece we will take a look at cross-validation and how it can be helpful for what we've been doing in our final projects. Cross-validation (colloquially called cross-val) will help us select the appropriate eplanatory variable or combination of explanatory variables for our linear regression models for predicting our outcome variable with the most accuracy. \n",
    "\n",
    "Throughout this piece I will be using my own intro stat final project group's data set, called \"babies\", which documents different physical and behavioral aspects of parents and the birth weights of their babies. For more information on what the variables and their respective values mean check out this [doc](https://docs.google.com/document/d/18R_gny_3b9zzn4zhHjbK09MwXSoT0NJsZNZCmuTu_po/edit). This data set is very specific and there are definitely some interesting aspects worth knowing about it (data collection, variables included, etc) that you can check out [here](https://docs.google.com/document/d/1QNnP3_OEKEgylCQNdS36R-yU5Y4hczN1FdcY5n0Lg-s/edit). We'll start by importing some packages for helper functions and tools we'll need later, similar to when we load packages using the library() function in R (for those unfamiliar with Python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import Block\n",
    "babies_data = pd.read_csv(\"babies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peak at the data in a similar way to how we can view data in RStudio by simply calling the dataframe (however, in this editor this trick only works as long as this is the last thing we call in our code block):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pluralty</th>\n",
       "      <th>outcome</th>\n",
       "      <th>date</th>\n",
       "      <th>gestation</th>\n",
       "      <th>sex</th>\n",
       "      <th>wt</th>\n",
       "      <th>parity</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>drace</th>\n",
       "      <th>dage</th>\n",
       "      <th>ded</th>\n",
       "      <th>dht</th>\n",
       "      <th>dwt</th>\n",
       "      <th>marital</th>\n",
       "      <th>inc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>time</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1411</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1499</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1576</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1504</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1425</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>9153</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1672</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>9163</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1712</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>9213</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1672</td>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>9229</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1680</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>9263</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1668</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1236 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  pluralty  outcome  date  gestation  sex   wt  parity  race  age  \\\n",
       "0       15         5        1  1411        284    1  120       1     8   27   \n",
       "1       20         5        1  1499        282    1  113       2     0   33   \n",
       "2       58         5        1  1576        279    1  128       1     0   28   \n",
       "3       61         5        1  1504        999    1  123       2     0   36   \n",
       "4       72         5        1  1425        282    1  108       1     0   23   \n",
       "...    ...       ...      ...   ...        ...  ...  ...     ...   ...  ...   \n",
       "1231  9153         5        1  1672        275    1  113       0     0   27   \n",
       "1232  9163         5        1  1712        265    1  128       1     0   24   \n",
       "1233  9213         5        1  1672        291    1  130       4     1   30   \n",
       "1234  9229         5        1  1680        281    1  125       0     0   21   \n",
       "1235  9263         5        1  1668        297    1  117       4     0   38   \n",
       "\n",
       "      ...  drace  dage  ded  dht  dwt  marital  inc  smoke  time  number  \n",
       "0     ...      8    31    5   65  110        1    1      0     0       0  \n",
       "1     ...      0    38    5   70  148        1    4      0     0       0  \n",
       "2     ...      5    32    1   99  999        1    2      1     1       1  \n",
       "3     ...      3    43    4   68  197        1    8      3     5       5  \n",
       "4     ...      0    24    5   99  999        1    1      1     1       5  \n",
       "...   ...    ...   ...  ...  ...  ...      ...  ...    ...   ...     ...  \n",
       "1231  ...      0    32    4   72  190        1    4      0     0       0  \n",
       "1232  ...      0    24    5   73  170        1    3      0     0       0  \n",
       "1233  ...      2    30    5   70  180        1    3      1     1       2  \n",
       "1234  ...      0    27    5   71  165        1    1      0     0       0  \n",
       "1235  ...      4    34    1   68  172        1    6      0     0       0  \n",
       "\n",
       "[1236 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babies_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set requires a bit of wrangling before we work with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only the columns we want\n",
    "bb_data = babies_data[['gestation', 'race', 'age', 'smoke', 'wt']]\n",
    "\n",
    "# Filter for unknowns\n",
    "bb_data = bb_data[bb_data['gestation'] != 999]\n",
    "bb_data = bb_data[bb_data['wt'] != 999]\n",
    "bb_data = bb_data[bb_data['race'] != 99]\n",
    "bb_data = bb_data[bb_data['age'] != 99]\n",
    "bb_data = bb_data[bb_data['smoke'] != 9]\n",
    "\n",
    "# race needs some extra pre-processing\n",
    "bb_data[\"race\"].replace({1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 2, 8: 4, 9: 5, 10: 6}, inplace=True)\n",
    "\n",
    "bb_data.to_csv(\"babies_wrangled.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "babies_wrangled = pd.read_csv(\"babies_wrangled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra function we will use later for cross-val\n",
    "\n",
    "def compute_mse(truth_vec, predict_vec):\n",
    "    return np.mean((truth_vec - predict_vec)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "\n",
    "Many people are surprised to know that linear regression is actually a form of machine learning! So we've all basically been doing machine learning for years and we didn't even know it, which is pretty cool when you think about it. \n",
    "\n",
    "The package we'll be using for our linear regression implementation, Numpy, can only fit the linear regression model to it's own data type called a Numpy array. Numpy arrays cannot contain non-numeric inputs, which means that if our data has categorical variables, we'll need to convert them to numbers. Luckily, the babies dataset already uses numbers to indicate the values of categorical variables. However, if you wanted to perform cross-val for linear regression on your own data set and your data has categorical variables with string values, the function described below will be helpful for you.\n",
    "\n",
    "For example, the `smoke` variable in our data set uses numbers to indicate\n",
    "cartegories as follows: 0 = never smoked, 1 = smokes now, 2 = smoked until pregnancy\n",
    "3 = smoked once, but not now, and 9 = unknown.\n",
    "\n",
    "For this problem, I've created a function `data_wrangle`. The function (implemented below) takes the csv filename for the data set you're using and a list of columns from the dataset \n",
    "that need to be converted to numerical values. The behavior of the function is summarized in the following steps:\n",
    "\n",
    "1. Import the data with `pandas` read_csv() function\n",
    "2. For each column listed as an input (ie. those with non-numerical \n",
    "   data):\n",
    "   * Determine the unique values in that column\n",
    "   * Convert the unique values in into unique numbers. \n",
    "3. Get the data's column names from \n",
    "   the observation rows.  \n",
    "4. Convert the data to a numpy array\n",
    "5. Return all of the column names in \n",
    "   order and the converted dataset as a tuple. \n",
    "   \n",
    "If you're unsure what the function is doing at any point, you can add print statements to print out variable values (syntax: \"print(data)\"). For those that are not comfortable with certain coding elements or conventions (like for-loops, function-writing, and methods), unfortunately these elements will not be explained here, but if you'd like to learn more about them I'd recommend taking CSC 111: Intro to Computer Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrangle(dataset_file, lst):\n",
    "    \n",
    "    # Import data with pandas\n",
    "    data = pd.read_csv(dataset_file)\n",
    "    \n",
    "    for column in lst:\n",
    "        # tip retrieved from https://cmdlinetips.com/2018/01/\n",
    "        # how-to-get-unique-values-from-a-column-in-pandas-data-frame/\n",
    "        unique_values = data[column].unique()\n",
    "        \n",
    "        numeric_val = 0\n",
    "        col_names = []\n",
    "        \n",
    "        for value in unique_values:\n",
    "            \n",
    "            # For clarity\n",
    "            print(value , \"in column\" , column , \"is now\" , numeric_val)\n",
    "            \n",
    "            data = data.replace(value, numeric_val)\n",
    "            numeric_val += 1\n",
    "            \n",
    "            # Extract the data's column names from the observation rows\n",
    "            col_names = data.loc[data[column] == value].columns\n",
    "            \n",
    "    if lst == []:\n",
    "        col_names = data.columns\n",
    "            \n",
    "    return np.array(col_names), data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-fold Cross-Validation\n",
    "\n",
    "Okay, I've been saying cross-validation a lot, but what actually is it? For this piece, we'll be using k-fold cross-validation for model selection, so I'll be focusing specifically on this type of cross-val. To understand cross-val, we'll first have to define some other concepts.\n",
    "\n",
    "In machine learning, we have this notion of train vs test. When we want to test the performance of a model, we'll usually split our data into training data and testing data. We train the model on the training data by fitting it to only that data, then test its performance on new data it hasn't seen before by asking it to predict values for this new data. But, when we're splitting data into training and testing data we run into some practical problems. What's the appropriate split? 50-50? Or something more extreme like 95-5? The more training data our model sees, the more accurate it will become. But if we leave too little data in either group, then we have a small sample size where we risk getting values that are not representative of the population. But what if we could overcome these issues by including all the data in our training and testing groups? This is what cross-val aims to to do.\n",
    "\n",
    "In k-fold cross-val, we divide our data into a certain number \"k\" of groups or \"folds\", and we let each group/fold take a turn being the test set, while we designate every other fold to be in the training set for a specific iteration. For a more concrete example of what this actually looks like, consider the following scenario:\n",
    "\n",
    "I split my data into 10 groups. I then select the first group and designate it as the testing set. The rest of the 9 groups are lumped together to become the training data set. I train my model (in our case our linear regression model) on the the data in the training set (groups 2-10), and then I ask it to predict the values of the outcome variable based on the values of the explanatory variables in the test set. After this, I compare the true values of the outcome variable in the test set to the values that my model predicted, and I compute the mean-squared error of the truth values vs the predicted values (this is basically taking the average of the squared values of the residuals). This is one iteration through the data. For a complete k-fold cross-val, we repeat the above process for the second group, the third group, and so on until every group has had a turn being the test set. We then compute the mean of all the mean-squared errors we computed for each iteration to get the k-fold cross-val error.\n",
    "\n",
    "Still feeling like the concept is a little too abstract? Let's take a look at cross-val in action and see if we can clear things up.\n",
    "\n",
    "For this next part I've created a function `kfold_CV` (in `hw5.py`) that implements k-fold \n",
    "cross-validation. \n",
    "The inputs, in order, are:\n",
    "1. The full dataset (as a numpy array)\n",
    "2. The header list (as in the list of variable/column names, in the \n",
    "   the order that they appear in the dataset)\n",
    "3. Input variables\n",
    "4. Output variables\n",
    "5. Value for _k_\n",
    "\n",
    "Using these inputs, `kfold_CV` is able to select the input and output columns from the data set, divide the data into k folds, and then iteratively choose one fold to be the test set for k rounds of training and testing. The linear regression model is trained on 100-100/k% of the \n",
    "data each iteration, with the input and output variables, and then is asked to \n",
    "predict the values of ouput variable based on the input variable values in the\n",
    "test set. The error is then computed from the true and predicted values for each iteration,\n",
    "with the final cross-val error being the mean of all these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_CV(data, col_names, inputs, output, k):\n",
    "    # Shuffle data so cross-val error is not coincidentally zero\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    ### Note: does not always split data evenly depending on number of rows and value of k\n",
    "    if data.shape[0]%k != 0:\n",
    "        maximum = data.shape[0]%k\n",
    "    else:\n",
    "        maximum = -1\n",
    "    \n",
    "    # If inputs or output is given as a single variable string convert to list\n",
    "    if type(inputs) != list:\n",
    "        inputs = [inputs]\n",
    "        \n",
    "    if type(output) != list:\n",
    "        output = [output]\n",
    "    \n",
    "    # Convert columns to np array if they are passed as a list for np.argwhere to function properly   \n",
    "    if type(col_names) == list:\n",
    "        col_names = np.array(col_names)\n",
    "    \n",
    "    input_col_inds = []\n",
    "    output_col_inds = []\n",
    "    \n",
    "    # Find numerical column index for input and output variables using list of ordered columns\n",
    "    for i in inputs:\n",
    "        input_col_inds.append(np.argwhere(col_names == str(i))[0][0])\n",
    "    for p in output: \n",
    "        output_col_inds.append(np.argwhere(col_names == str(p))[0][0])\n",
    "        \n",
    "    num_rows = data.shape[0]\n",
    "    \n",
    "    start = 0\n",
    "    end = num_rows//k\n",
    "    count = 0\n",
    "    test_errors = []\n",
    "\n",
    "    # Loop over all folds in the data set, letting each act as the test set\n",
    "    for fold in range(k):\n",
    "        \n",
    "        # Split data into train and test\n",
    "        test_data = data[start:end, :]\n",
    "        train_indices = list(set(range(num_rows)).difference(list(set(range(start, end)))))\n",
    "        train_data = data[train_indices, :]\n",
    "        \n",
    "        # Create and train a model\n",
    "        lm = linear_model.LinearRegression()\n",
    "        mod = lm.fit(train_data[:, input_col_inds], train_data[:, output_col_inds])\n",
    "    \n",
    "        # Compute the testing error and add it to the list of testing errors\n",
    "        test_preds = mod.predict(test_data[:, input_col_inds])\n",
    "        test_error = compute_mse(test_preds, test_data[:, output_col_inds])\n",
    "        test_errors.append(test_error)\n",
    "                             \n",
    "        start = start + num_rows//k\n",
    "        end = start + num_rows//k\n",
    "        count += 1\n",
    "        \n",
    "        if count <= maximum:\n",
    "            start += 1\n",
    "            end += 1\n",
    "        \n",
    "    # Compute the cross-val error\n",
    "    return np.mean(test_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 10-fold Cross-Validation to Pick Explanatory Variables\n",
    "\n",
    "Now that we've defined our cross-val function, we can use it to select the best combination of explanatory variables for our linear regression model. Below I've tried all combinations of one, two, three, and finally four variables to see which one yields the lowest cross-val error for our data set. I decided to use 10-fold cross-validation because a 90% train - 10% test split is usually considered a pretty good train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = data_wrangle(\"babies_wrangled.csv\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross-val for gestation vs weight is  278.6868521406365\n",
      "10-fold cross-val for race vs weight is  324.17065825257055\n",
      "10-fold cross-val for age vs weight is  332.8886852969867\n",
      "10-fold cross-val for smoke vs weight is  332.8530570981478\n"
     ]
    }
   ],
   "source": [
    "# Transform data\n",
    "data_np = data_wrangle(\"babies_wrangled.csv\", [])\n",
    "\n",
    "all_errors = []\n",
    "\n",
    "## One-variable combinations\n",
    "\n",
    "# Input: gestation\n",
    "g_error = kfold_CV(data_np[1], data_np[0], [\"gestation\"], [\"wt\"], 10)\n",
    "all_errors.append(g_error)\n",
    "print(\"10-fold cross-val for gestation vs weight is \", g_error)\n",
    "\n",
    "# Input: race\n",
    "r_error = kfold_CV(data_np[1], data_np[0], [\"race\"], [\"wt\"], 10)\n",
    "all_errors.append(r_error)\n",
    "print(\"10-fold cross-val for race vs weight is \", r_error)\n",
    "\n",
    "# Input: age\n",
    "a_error = kfold_CV(data_np[1], data_np[0], [\"age\"], [\"wt\"], 10)\n",
    "all_errors.append(a_error)\n",
    "print(\"10-fold cross-val for age vs weight is \", a_error)\n",
    "\n",
    "# Input: smoke\n",
    "s_error = kfold_CV(data_np[1], data_np[0], [\"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(s_error)\n",
    "print(\"10-fold cross-val for smoke vs weight is \", s_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross-val for gestation and race vs weight is  275.99051625522696\n",
      "10-fold cross-val for gestation and age vs weight is  278.22216196184667\n",
      "10-fold cross-val for gestation and smoke vs weight is  279.2821110010082\n",
      "10-fold cross-val for race and age vs weight is  324.3208239907482\n",
      "10-fold cross-val for race and smoke vs weight is  324.54081690217293\n",
      "10-fold cross-val for age and smoke vs weight is  333.62879561646594\n"
     ]
    }
   ],
   "source": [
    "## Two-variable combinations\n",
    "\n",
    "# Input: gestation and race\n",
    "gr_error = kfold_CV(data_np[1], data_np[0], [\"gestation\", \"race\"], [\"wt\"], 10)\n",
    "all_errors.append(gr_error)\n",
    "print(\"10-fold cross-val for gestation and race vs weight is \", gr_error)\n",
    "\n",
    "# Input: gestation and age\n",
    "ga_error = kfold_CV(data_np[1], data_np[0], [\"gestation\", \"age\"], [\"wt\"], 10)\n",
    "all_errors.append(ga_error)\n",
    "print(\"10-fold cross-val for gestation and age vs weight is \", ga_error)\n",
    "\n",
    "# Input: gestation and smoke\n",
    "gs_error = kfold_CV(data_np[1], data_np[0], [\"gestation\", \"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(gs_error)\n",
    "print(\"10-fold cross-val for gestation and smoke vs weight is \", gs_error)\n",
    "\n",
    "# Input: race and age\n",
    "ra_error = kfold_CV(data_np[1], data_np[0], [\"race\", \"age\"], [\"wt\"], 10)\n",
    "all_errors.append(ra_error)\n",
    "print(\"10-fold cross-val for race and age vs weight is \", ra_error)\n",
    "\n",
    "# Input: race and smoke\n",
    "rs_error = kfold_CV(data_np[1], data_np[0], [\"race\", \"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(rs_error)\n",
    "print(\"10-fold cross-val for race and smoke vs weight is \", rs_error)\n",
    "\n",
    "# Input: age and smoke\n",
    "as_error = kfold_CV(data_np[1], data_np[0], [\"age\", \"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(as_error)\n",
    "print(\"10-fold cross-val for age and smoke vs weight is \", as_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross-val for gestation, race, and age vs weight is  274.5246321507387\n",
      "10-fold cross-val for gestation, race, and smoke vs weight is  276.2099936870532\n",
      "10-fold cross-val for gestation, age, and smoke vs weight is  278.5582633434022\n",
      "10-fold cross-val for race, age, and smoke vs weight is  323.9854941339939\n"
     ]
    }
   ],
   "source": [
    "## Three-variable combinations\n",
    "\n",
    "# Input: gestation, race, and age\n",
    "gra_error = kfold_CV(data_np[1], data_np[0], [\"gestation\", \"race\", \"age\"], [\"wt\"], 10)\n",
    "all_errors.append(gra_error)\n",
    "print(\"10-fold cross-val for gestation, race, and age vs weight is \", gra_error)\n",
    "\n",
    "# Input: gestation, race, and smoke\n",
    "grs_error = kfold_CV(data_np[1], data_np[0], [\"gestation\", \"race\", \"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(grs_error)\n",
    "print(\"10-fold cross-val for gestation, race, and smoke vs weight is \", grs_error)\n",
    "\n",
    "# Input: gestation, age, and smoke\n",
    "gas_error = kfold_CV(data_np[1], data_np[0], [\"gestation\", \"age\", \"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(gas_error)\n",
    "print(\"10-fold cross-val for gestation, age, and smoke vs weight is \", gas_error)\n",
    "\n",
    "# Input: race, age, and smoke\n",
    "ras_error = kfold_CV(data_np[1], data_np[0], [\"race\", \"age\", \"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(ras_error)\n",
    "print(\"10-fold cross-val for race, age, and smoke vs weight is \", ras_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross-val for gestation, race, age, and smoke vs weight is  276.2084872717013\n"
     ]
    }
   ],
   "source": [
    "## Four-Variable Combination\n",
    "\n",
    "# Input: gestation, race, age, and smoke\n",
    "gras_error = kfold_CV(data_np[1], data_np[0], [\"gestation\", \"race\", \"age\", \"smoke\"], [\"wt\"], 10)\n",
    "all_errors.append(gras_error)\n",
    "print(\"10-fold cross-val for gestation, race, age, and smoke vs weight is \", gras_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum error is 274.5246321507387 , which is the 10-fold cross-val error for \n",
      "gestation, race, and age as input variables\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum error is\", min(all_errors), \n",
    "      \", which is the 10-fold cross-val error for \\ngestation, race, and age as input variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the best combination of expalnatory variables for predicting birth weight with a linear regression model is the length of gestation, the mother's race, and the mother's age, because this combination yielded the lowest cross-val error. This means that this combination predicted infant birth weight for the test set with the least deviation from the true birth weight values across 10 different iterations of splitting 90% of the data into train, and 10% to test, out of all the possible explanatory variable combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the full model\n",
    "\n",
    "Now that we've selected our optimal combination of variables, we can fit our model to all the data instead of training it on only a fraction of the data. When we use all of the data instead of a fraction of it, we have more points to fit our model to, making our model as accurate a representation of the data as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope coefficients are 0.4446675816423984 -1.5223872112036072 and 0.17934673343344268 \n",
      "intercept is -8.413038906983132\n"
     ]
    }
   ],
   "source": [
    "# Set up linear regression\n",
    "lm2 = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the linear regression to the data\n",
    "model2 = lm2.fit(data_np[1][:, 0:3], data_np[1][:, 4])\n",
    "\n",
    "# Extract the coefficients\n",
    "m = model2.coef_\n",
    "b = model2.intercept_\n",
    "print(\"slope coefficients are\", m[0], m[1], \"and\", m[2], \"\\nintercept is\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can write the equation for the full model as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\widehat{birth\\: weight} = .44 \\cdot gestation -1.52 \\cdot race + .179 \\cdot age - 8.41 \\: ounces\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Now we know how to select the appropriate explanatory variable combination for our outcome variable using cross-validation! You might be wondering at this point: wait, is 275 a large cross-val error to obtain in this scenario? How can we visualize the accuracy of our model in four dimensions? These are of course good questions, but they are unfortunately outside the scope of this piece. If we were trying to select the best variable combinations for models we know how to visualize, we might only use cross-val with one or two explanatory variables for our linear regression. We might also dimension reduce our data to better visualize it, which I will talk about next in the piece on PCA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
